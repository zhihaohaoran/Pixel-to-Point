# Description: This script evaluates the performance of the MultiTaskGP model with different nu values.
# The script uses the Chamfer Distance metric to evaluate the model's performance.
# The script defines a MultiTaskGPModel class that extends the ExactGP class from GPyTorch.
# The model is trained with different nu values and evaluated using R² Score, RMSE, and Chamfer Distance.
# The results are displayed for each nu value.
# The script also defines a function to calculate the Chamfer Distance between two sets of points.
# The function calculates the forward and backward Chamfer Distance between two sets of points.
# The script generates test data around the input points for evaluation.
# The test data is generated by moving the points in different directions.
# The script uses the MultiTaskGPModel class to train the model with different nu values.
# The model is trained using the Adam optimizer with a learning rate of 0.01 and weight decay of 1e-6.
# The training loop runs for 750 iterations to optimize the model parameters.
# The model is evaluated on the test data, and the R² Score, RMSE, and Chamfer Distance are calculated.
# The script evaluates the model with different nu values (0.5, 1.5, 2.5) and displays the results.
# The results include the R² Score, RMSE, and Chamfer Distance for each nu value.
import torch
import gpytorch
from gpytorch.likelihoods import MultitaskGaussianLikelihood
from gpytorch.distributions import MultitaskMultivariateNormal, MultivariateNormal
from sklearn.metrics import r2_score, mean_squared_error
from gpytorch.means import ConstantMean
from gpytorch.kernels import RBFKernel, ScaleKernel, MaternKernel
from gpytorch.distributions import MultitaskMultivariateNormal, MultivariateNormal
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from scipy.interpolate import make_interp_spline
import numpy as np
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use the first GPU

print(torch.cuda.is_available())  # Should return True
print(torch.cuda.device_count())  # Should return the number of GPUs
print(torch.cuda.current_device())  # Should print the current device index
print(torch.cuda.get_device_name(0))  # Should print the GPU name

# Load and prepare data
file_path_points3d = '/home/staff/zhihao/Downloads/3dgs/mogp/gp_evaluation/mipnerf360/360_v2/stump/sparse/0/points3D.txt'
depth_file_path = '/home/staff/zhihao/Downloads/3dgs/mogp/gp_evaluation/mipnerf360/360_v2/stump/depth/kitchen.npy'

# Load points3D from file
def load_points3D(file_path):
    points3d_dict = {}
    with open(file_path, 'r') as file:
        for line in file:
            if line.startswith('#') or len(line.strip()) == 0:
                continue
            parts = line.split()
            point_id = int(parts[0])
            x, y, z = map(float, parts[1:4])
            r, g, b = map(float, parts[4:7])
            points3d_dict[point_id] = [x, y, z, r / 255.0, g / 255.0, b / 255.0]
    return points3d_dict


points3d_dict = load_points3D(file_path_points3d)


# Parse images file
def parse_images_file(file_path, points3d_dict):
    valid_data = {}
    with open(file_path, 'r') as file:
        lines = file.readlines()
        i = 0
        while i < len(lines):
            if lines[i].startswith('#') or not lines[i].strip():
                i += 1
                continue

            image_data = lines[i].strip().split()
            image_name = image_data[9]
            i += 1
            keypoints_data = lines[i].strip().split()
            points2d = []
            k = 0
            while k < len(keypoints_data):
                x, y = map(float, keypoints_data[k:k + 2])
                point3d_id = int(keypoints_data[k + 2])
                if point3d_id != -1 and point3d_id in points3d_dict:
                    points2d.append((x, y) + tuple(points3d_dict[point3d_id]))
                k += 3
            if points2d:
                valid_data[image_name] = points2d
            i += 1

    return valid_data


file_path_images = '/home/staff/zhihao/Downloads/3dgs/mogp/gp_evaluation/mipnerf360/360_v2/kitchen/sparse/0/images.txt'
valid_data = parse_images_file(file_path_images, points3d_dict)
def generate_test_data(valid_data, depth_file_path):
    data_by_image = {}
    depth_images = np.load(depth_file_path)
    image_indices = {name: idx for idx, name in enumerate(sorted(valid_data.keys()))}


    movements = {
        'left': (-20, 0),
        'right': (20, 0),
        'up': (0, -20),
        'down': (0, 20),
        'up-left': (-20, -20),
        'up-right': (20, -20),
        'down-left': (-20, 20),
        'down-right': (20, 20)
    }


    for image_name, data_points in valid_data.items():
        input_data = []
        output_data = []
        test_data = []

        current_depth_image = depth_images[image_indices[image_name]]
        image_height, image_width = current_depth_image.shape

        for point in data_points:
            x, y = int(point[0]), int(point[1])
            if x < 0 or x >= image_width or y < 0 or y >= image_height:
                # Handle out-of-bounds case, skip or adjust
                continue
            original_depth = current_depth_image[y, x]
            input_data.append([x, y, original_depth])
            output_data.append(point[2:])

            # Generate test data around the point using new movements
            for direction, (dx, dy) in movements.items():
                new_x, new_y = x + dx, y + dy
                if 0 <= new_x < image_width and 0 <= new_y < image_height:
                    new_depth = current_depth_image[new_y, new_x]
                    test_data.append([new_x, new_y, new_depth])

        # Normalize data
        input_data = np.array(input_data, dtype=float)
        test_data = np.array(test_data, dtype=float)
        input_data[:, 0] /= image_width  # Normalize x coordinates to [0, 1]
        input_data[:, 1] /= image_height  # Normalize y coordinates to [0, 1]
        test_data[:, 0] /= image_width  # Normalize x coordinates
        test_data[:, 1] /= image_height  # Normalize y coordinates

        # Storing data in the dictionary
        data_by_image[image_name] = {
            'input': input_data,
            'output': np.array(output_data, dtype=float),
            'test': test_data
        }

    return data_by_image


data_by_image_new = generate_test_data(valid_data, depth_file_path)

scaler_output = MinMaxScaler()
input_data_normalized = data_by_image_new['000012.JPG']['input']
output_data_normalized = scaler_output.fit_transform(data_by_image_new['000012.JPG']['output'])

# Split data into train and test sets
train_input, test_input, train_output, test_output = train_test_split(input_data_normalized, output_data_normalized,
                                                                      test_size=0.2, random_state=42)

train_input = torch.tensor(train_input, dtype=torch.float32)
train_output = torch.tensor(train_output, dtype=torch.float32)
test_input = torch.tensor(test_input, dtype=torch.float32)
test_output = torch.tensor(test_output, dtype=torch.float32)


# Function to calculate Chamfer Distance
def chamfer_distance(pred_points, true_points):
    pred_expanded = pred_points.unsqueeze(1)  # (N, 1, D)
    true_expanded = true_points.unsqueeze(0)  # (1, M, D)
    distances = torch.norm(pred_expanded - true_expanded, dim=-1)  # (N, M)
    forward_cd = torch.mean(torch.min(distances, dim=1)[0])
    backward_cd = torch.mean(torch.min(distances, dim=0)[0])
    return forward_cd + backward_cd


# Function to create and train the MultiTaskGPModel for a given nu value
def train_model_with_nu(nu, train_input, train_output, test_input, test_output):
    likelihood = MultitaskGaussianLikelihood(num_tasks=6).to(device)
    model = MultiTaskGPModel(train_input, train_output, likelihood, num_tasks=6, nu=nu).to(device)

    model.train()
    likelihood.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-6)
    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)

    # Training loop
    training_iterations = 1000
    for i in range(training_iterations):
        optimizer.zero_grad()
        output = model(train_input)
        loss = -mll(output, train_output)
        loss.backward()
        optimizer.step()

    # Evaluation
    model.eval()
    likelihood.eval()
    with torch.no_grad(), gpytorch.settings.fast_pred_var():
        test_output_pred = model(test_input)
        mean_prediction = test_output_pred.mean.cpu().numpy()
        true_output = test_output.cpu().numpy()

    # Calculate R² Score, RMSE, and Chamfer Distance
    r2 = r2_score(true_output, mean_prediction)
    rmse = np.sqrt(mean_squared_error(true_output, mean_prediction))

    mean_prediction_tensor = torch.tensor(mean_prediction, dtype=torch.float32)
    true_output_tensor = torch.tensor(true_output, dtype=torch.float32)
    chamfer_dist = chamfer_distance(mean_prediction_tensor, true_output_tensor).item()

    return r2, rmse, chamfer_dist


# Define the MultiTaskGPModel class
class MultiTaskGPModel(gpytorch.models.ExactGP):
    def __init__(self, train_x, train_y, likelihood, num_tasks, nu):
        super(MultiTaskGPModel, self).__init__(train_x, train_y, likelihood)
        self.mean_module = ConstantMean(batch_shape=torch.Size([num_tasks]))
        self.covar_module = ScaleKernel(
            MaternKernel(nu=nu, batch_shape=torch.Size([num_tasks])),
            batch_shape=torch.Size([num_tasks])
        )

    def forward(self, x):
        mean_x = self.mean_module(x)
        covar_x = self.covar_module(x)
        return MultitaskMultivariateNormal.from_batch_mvn(MultivariateNormal(mean_x, covar_x))


# Device setup
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
train_input = train_input.to(device)
train_output = train_output.to(device)
test_input = test_input.to(device)
test_output = test_output.to(device)

# Evaluate the model with different nu values
nu_values = [0.5, 1.5, 2.5]
results = []

for nu in nu_values:
    print(f"Training model with nu = {nu}")
    r2, rmse, chamfer_dist = train_model_with_nu(nu, train_input, train_output, test_input, test_output)
    results.append((nu, r2, rmse, chamfer_dist))
    print(f"nu: {nu}, R^2 Score: {r2:.3f}, RMSE: {rmse:.3f}, Chamfer Distance: {chamfer_dist:.3f}")

# Display results
for nu, r2, rmse, chamfer_dist in results:
    print(f"nu: {nu}, R^2 Score: {r2:.3f}, RMSE: {rmse:.3f}, CD: {chamfer_dist:.3f}")

